<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Self attention models - part 1">
    <title>Self attention models - part 1</title>
    <link rel="stylesheet" href="../../styles.css">
    
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
</head>
<body>
    <!-- Header loaded dynamically -->
    <div id="header-placeholder"></div>

    <!-- Main Content -->
    <main class="main-content">
        <div class="container">
            <article class="blog-article">
                <!-- Back to blog link -->
                <nav class="breadcrumb">
                    <a href="../../blog.html" class="breadcrumb-link">← Back to Blog</a>
                </nav>

                <!-- Article Header -->
                <header class="article-header">
                    <h1 class="article-title">Self attention models - part 1</h1>
                    <p class="article-meta">Published: <time datetime="2025-12-17">December 17, 2025</time></p>
                </header>

                <!-- Article Content -->
                <div class="article-content">
<h1 id="self-attention-models-an-intuitive-introduction">Self-Attention Models: An Intuitive Introduction</h1><p>Hi there, in this post, I present my notes on self-attention models, building upon the attention mechanism discussed in my previous article. This content is based on Shusen Wang’s explanations of self-attention with RNNs, combined with insights from other resources. For more details on the basic attention mechanism, see my <a href="../attention_models/">introduction article to attention models</a>.</p><h2 id="what-is-attention">What is Attention?</h2><p>Attention models (as previously discussed) when combined with the encoder and decoder RNNs allow tokens from the RNN decoder, at each step, to pay attention to all of the outputs of the encoder RNN. For translation tasks, this is useful when translating a word, to know where to look in the encoder part. Then it calculates similarities and weights, to give a weight for each token from the encoder as a relevance criteria to the current step.</p><h2 id="what-is-self-attention">What is Self-Attention?</h2><p><strong>Self-attention is an extension of the attention mechanism.</strong> In other words, the attention mechanism when applied on a single RNN, allows each token to take a look (pay attention) on all other tokens from the same RNN.</p><p>In a transformer, self-attention, when used in the encoder for example, allows words to be encoded as a direct function of their context. This is useful for example when encoding the word “apple”. Depending on their surrounding words, the word “apple” will be encoded as being the “apple” (fruit) or “apple” (the company).</p><h2 id="self-attention-vs.-masked-self-attention">Self-Attention vs. Masked Self-Attention</h2><p>Shusen Wang, in his videos, explains the concept of self-attention by combining RNNs and the attention mechanism. In his videos, he presents it as self-attention, however, what he presents is actually <strong>masked self-attention</strong>.</p><p>The difference between self-attention and masked self-attention is: - <strong>Self-attention</strong>: compares each token with all the other tokens in the sentence - <strong>Masked self-attention</strong>: for example in a case of translation, compares a generated word with all the previous words, but not the next words, since they are not yet generated</p><figure><img src="images/self_attention_basic.png" alt="" /><figcaption>Self-Attention: each token attends to all others</figcaption></figure><p><em>Figure: In self-attention, each token (word) attends to all other tokens in the same sentence.</em></p><figure><img src="images/masked_self_attention_basic.png" alt="" /><figcaption>Masked Self-Attention: each token attends only to previous tokens</figcaption></figure><p><em>Figure: In masked self-attention (as used in decoders), each token attends only to previous (or current) tokens, and not to future tokens.</em></p><p><strong>Terminology:</strong> The token we are comparing is called the <strong>query</strong>, the tokens to which we compare are called the <strong>keys</strong>.</p><h2 id="self-attention-with-rnns-step-by-step-example">Self-Attention with RNNs: Step-by-Step Example</h2><p>Here are my notes on Shusen Wang’s example of self-attention with RNN, step by step.</p><h3 id="step-1">Step 1</h3><figure><img src="images/SA_1.png" alt="" /><figcaption>Self-Attention on RNNs: Detailed Example</figcaption></figure><p><em>Figure: Visualization of self-attention mechanism as explained in Shusen Wang’s video. Each token’s representation is updated by attending to all (or previous, if masked) hidden states in the sequence, resulting in context-aware feature vectors.</em></p><p>In a simple RNN as in our previous article, <span class="math inline"><em>h</em><sub>1</sub></span> is a function of <span class="math inline"><em>h</em><sub>0</sub></span> and <span class="math inline"><em>x</em><sub>1</sub></span>. However, in self-attention, it’s a function of <span class="math inline"><em>x</em><sub>1</sub></span> and the context vector.</p><p><br /><span class="math display"><em>h</em><sub>1</sub> = tanh (<em>A</em> ⋅ [<em>x</em><sub>1</sub>, <em>c</em><sub>0</sub>])</span><br /></p><p>The context vector is a weighted average of all the previous hidden states. At the beginning, <span class="math inline"><em>c</em><sub>0</sub> = 0</span> and <span class="math inline"><em>c</em><sub>1</sub> = <em>h</em><sub>1</sub></span> since there is no previous <span class="math inline"><em>h</em><sub><em>i</em></sub></span> vectors.</p><p>A weighted average implies weights for each hidden state. Each weight is calculated with the align function (it’s like a similarity function, the bigger the similarity is, the bigger the weight). In general, the weights <span class="math inline"><em>α</em></span> are calculated as:</p><p><br /><span class="math display"><em>α</em><sub>currentstep, <em>i</em></sub> = align(<em>h</em><sub><em>i</em></sub>, <em>h</em><sub>currentstep</sub>)</span><br /></p><p>In our current step, the weight is just an align function between the first hidden state and itself:</p><p><br /><span class="math display"><em>α</em><sub>1, 1</sub> = align(<em>h</em><sub>1</sub>, <em>h</em><sub>1</sub>)</span><br /></p><h3 id="step-2">Step 2</h3><figure><img src="images/SA_2.png" alt="" /><figcaption>Self-Attention Step 2: Attention scores over two tokens</figcaption></figure><p><em>Figure: At step 2, the token computes attention weights with respect to all previous and current tokens’ hidden states. Note the weights are different than the weights of the first step.</em></p><p>Next, <span class="math inline"><em>h</em><sub>2</sub></span> is calculated as:</p><p><br /><span class="math display"><em>h</em><sub>2</sub> = tanh (<em>A</em> ⋅ [<em>x</em><sub>2</sub>, <em>c</em><sub>1</sub>])</span><br /></p><p>So <span class="math inline"><em>h</em><sub>2</sub></span> knows both <span class="math inline"><em>x</em><sub>2</sub></span> and <span class="math inline"><em>x</em><sub>1</sub></span> through the context vector.</p><p>To calculate the context vector <span class="math inline"><em>c</em><sub>2</sub></span>, we need to calculate a weighted average of all the present hidden states. So we should first calculate weights:</p><p><br /><span class="math display"><em>α</em><sub>2, 1</sub> = align(<em>h</em><sub>1</sub>, <em>h</em><sub>2</sub>)</span><br /></p><p><br /><span class="math display"><em>α</em><sub>2, 2</sub> = align(<em>h</em><sub>2</sub>, <em>h</em><sub>2</sub>)</span><br /></p><p>Then the context vector for this step is:</p><p><br /><span class="math display"><em>c</em><sub>2</sub> = <em>α</em><sub>2, 1</sub> ⋅ <em>h</em><sub>1</sub> + <em>α</em><sub>2, 2</sub> ⋅ <em>h</em><sub>2</sub></span><br /></p><h3 id="step-3">Step 3</h3><figure><img src="images/SA_3.png" alt="" /><figcaption>Self-Attention Step 3: Attention scores over all tokens</figcaption></figure><p><em>Figure: At step 3, the token computes attention weights (alphas) with respect to all previous and current tokens’ hidden states. This determines how much information from each position is included in the context vector for the current step. The context vector is then used, together with the current input, to update the representation for this token.</em></p><p>Again, <span class="math inline"><em>h</em><sub>3</sub></span> is calculated as:</p><p><br /><span class="math display"><em>h</em><sub>3</sub> = tanh (<em>A</em> ⋅ [<em>x</em><sub>3</sub>, <em>c</em><sub>2</sub>])</span><br /></p><p>Then we recalculate all the alphas:</p><p><br /><span class="math display"><em>α</em><sub>3, 1</sub> = align(<em>h</em><sub>3</sub>, <em>h</em><sub>1</sub>)</span><br /></p><p><br /><span class="math display"><em>α</em><sub>3, 2</sub> = align(<em>h</em><sub>3</sub>, <em>h</em><sub>2</sub>)</span><br /></p><p><br /><span class="math display"><em>α</em><sub>3, 3</sub> = align(<em>h</em><sub>3</sub>, <em>h</em><sub>3</sub>)</span><br /></p><p>The context vector <span class="math inline"><em>c</em><sub>3</sub></span> would then be:</p><p><br /><span class="math display"><em>c</em><sub>3</sub> = <em>α</em><sub>3, 1</sub> ⋅ <em>h</em><sub>1</sub> + <em>α</em><sub>3, 2</sub> ⋅ <em>h</em><sub>2</sub> + <em>α</em><sub>3, 3</sub> ⋅ <em>h</em><sub>3</sub></span><br /></p><h2 id="general-pattern">General Pattern</h2><p>From the examples above, we can see the general pattern for self-attention with RNNs:</p><ol type="1"><li><p><strong>At each step <span class="math inline"><em>t</em></span></strong>, the hidden state <span class="math inline"><em>h</em><sub><em>t</em></sub></span> is computed as: <br /><span class="math display"><em>h</em><sub><em>t</em></sub> = tanh (<em>A</em> ⋅ [<em>x</em><sub><em>t</em></sub>, <em>c</em><sub><em>t</em> − 1</sub>])</span><br /> where <span class="math inline"><em>c</em><sub><em>t</em> − 1</sub></span> is the context vector from the previous step.</p></li><li><p><strong>Attention weights</strong> are calculated for all previous and current hidden states: <br /><span class="math display"><em>α</em><sub><em>t</em>, <em>i</em></sub> = align(<em>h</em><sub><em>t</em></sub>, <em>h</em><sub><em>i</em></sub>)  for <em>i</em> = 1, 2, …, <em>t</em></span><br /></p></li><li><p><strong>The context vector</strong> <span class="math inline"><em>c</em><sub><em>t</em></sub></span> is computed as a weighted sum: <br /><span class="math display">$$c_t = sum_{i=1}^{t} lpha_{t,i} ot h_i$$</span><br /></p></li></ol><p>This process allows each token to incorporate information from all previous tokens (and itself) in the sequence, creating context-aware representations that are essential for understanding the meaning of words based on their surrounding context.</p><h2 id="summary">Summary</h2><p>Self-attention extends the attention mechanism to work within a single sequence, allowing each token to attend to all other tokens in the same sequence. This creates rich, context-dependent representations that are crucial for modern NLP models like transformers. The key difference from standard attention is that self-attention operates on a single RNN rather than between encoder and decoder RNNs.</p><p>In masked self-attention (used in decoders), tokens can only attend to previous tokens, preventing information leakage from future tokens during generation tasks.</p>
                </div>
            </article>
        </div>
    </main>

    <!-- Footer loaded dynamically -->
    <div id="footer-placeholder"></div>

    <script src="../../data/cv-data.js"></script>
    <script src="../../js/script.js"></script>
    
    <!-- Render math equations with KaTeX -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            if (typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '$', right: '$', display: false},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '\\(', right: '\\)', display: false}
                    ],
                    throwOnError: false
                });
            }
        });
    </script>
</body>
</html>

